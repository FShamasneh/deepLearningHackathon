"# deepLearningHackathon" 
1.	In module 1, we will be covering the practical aspects of deep learning. We will see how to split the training, validation and test sets from the given data. We will also be covering topics like regularization, dropout, normalization, etc. that help us make our model more efficient.
2.	In module 2, we will discuss the concept of a mini-batch gradient descent and a few more optimizers like Momentum, RMSprop, and ADAM.
3.	In the last module, we will see how different hyperparameters can be tuned to improve the modelâ€™s efficiency. We will also cover the concept of Batch Normalization and how to solve a multi-class classification challenge.
